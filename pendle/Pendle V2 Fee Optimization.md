# Background

In Pendle V2, a variety of AMM pools are available, allowing traders to swap assets for PT, YT, or vice versa. The swap fee plays a crucial role in shaping the user experience. If the fee is set incorrectly, it can have the following effects:

- **Too High**: This would deter traders from swapping, ultimately reducing the profits of LPs and vePendle voters. Although the fee per transaction may increase, the overall volume of swaps would decrease.
- **Too Low**: This would undermine the profits of LPs and vePendle voters, even though the volume of swaps might increase significantly.

This situation is analogous to a **market competition model** in economics. In such models, a company’s revenue is given by $$R= P \times Q$$, where $$P$$ is the price and $$Q$$ is the quantity sold. If the price is set incorrectly, the revenue will not be optimized, even though the quantity $$Q$$ may increase.

Previously, our team introduced the “Efficient Ratio” as an indicator to measure the effectiveness of fee settings in specific pools. In this data-driven report, we aim to explore the following:

- Has the “Efficient Ratio” functioned well in evaluating the effectiveness of fee settings? If not, is there a more suitable alternative indicator?
- How do different fee tiers affect the “Efficient Ratio”? What is the optimal range according to historical data?

# Fee Calculation

In Pendle V2 AMM, there are two types of fees:

- **Explicit Fee**: These are the fees charged according to the specific fee tier of each pool, as displayed in the app. The distribution is as follows:
  - 20% is allocated to LP holders.
  - 80% is distributed to vePENDLE voters.
- **Implicit Fee**: These fees are generated by the formula used to quote the price for each swap. 
  - The formula is “relatively protective of the AMM pool,” meaning it quotes a conservative price to prevent potential exploitation of the AMM. The larger the trade, the higher the implicit fees.
  - They are not the same as price impact (slippage) in general. They are “on the top” of price impact.
  - 100% is allocated to the LP holders

In this section, we will provide a detailed explanation of these two types of fees.

## Explicit Fees

In V2, the explicit fees are described in the whitepaper `V2_AMM.pdf` and implemented in the smart contracts `MarketMathCore.sol` (Core Logic) and `PendleMarketV3.sol`.

The whitepaper defines the amount of assets going in, denoted as $$d_{asset}$$  as a function of the amount of PT tokens going out, denoted as $$d_{pt}$$:

$$
d_{asset}=\frac{d_{pt}}{exchangeRate(t)}\div or \times feeRateRoot^{yearsToExpiry(t)}
$$
where,

- $$exchangeRate(t)$$ is the spot exchange rate of asset in PT at time $$t$$, excluding any fees
- $$feeRateRoot=1+feetier$$
- $$yearsToExpiry(t)$$ is the time remaining until expiry, measured in years

Accordingly, the fee can be computed as follows:

- if $$d_{pt}>0$$ i.e. swapping assets for PT, then 

  $$
  d_{asset}=\frac{d_{pt}}{exchangeRate(t)}\times feeRateRoot^{yearsToExpiry(t)}
  $$
  The fee is:

  $$
  fee=\frac{d_{pt}}{exchangeRate(t)}(feeRateRoot^{yearsToExpiry(t)}-1)
  $$

- if $$d_{pt}<0$$  i.e. swapping PT for assets, then 

  $$
  d_{asset}=\frac{d_{pt}}{exchangeRate(t)}\div feeRateRoot^{yearsToExpiry(t)}
  $$
  The fee is:
  
  $$
  fee=-\frac{d_{pt}}{exchangeRate(t)}(\frac{1-feeRateRoot^{yearsToExpiry(t)}}{feeRateRoot^{yearsToExpiry(t)}})
  $$
  

This logic is implemented in the `calcTrade` function of `MarketMathCore.sol`. The relevant source code is as follows:

```solidity
function calcTrade(
        MarketState memory market,
        MarketPreCompute memory comp,
        PYIndex index,
        int256 netPtToAccount
    ) internal pure returns (int256 netSyToAccount, int256 netSyFee, int256 netSyToReserve) {
        int256 preFeeExchangeRate = _getExchangeRate(
            market.totalPt,
            comp.totalAsset,
            comp.rateScalar,
            comp.rateAnchor,
            netPtToAccount
        );

        int256 preFeeAssetToAccount = netPtToAccount.divDown(preFeeExchangeRate).neg();
        int256 fee = comp.feeRate;

        if (netPtToAccount > 0) {
            int256 postFeeExchangeRate = preFeeExchangeRate.divDown(fee);
            if (postFeeExchangeRate < PMath.IONE) revert Errors.MarketExchangeRateBelowOne(postFeeExchangeRate);

            fee = preFeeAssetToAccount.mulDown(PMath.IONE - fee);
        } else {
            fee = ((preFeeAssetToAccount * (PMath.IONE - fee)) / fee).neg();
        }

        int256 netAssetToReserve = (fee * market.reserveFeePercent.Int()) / PERCENTAGE_DECIMALS;
        int256 netAssetToAccount = preFeeAssetToAccount - fee;

        netSyToAccount = netAssetToAccount < 0
            ? index.assetToSyUp(netAssetToAccount)
            : index.assetToSy(netAssetToAccount);
        netSyFee = index.assetToSy(fee);
        netSyToReserve = index.assetToSy(netAssetToReserve);
    }
```

where:

1. `fee`  corresponds to $$feeRateRoot^{yearsToExpiry(t)}$$ as described in the whitepaper.
2. `netPtToAccount` corresponds to $$d_{pt}$$ in the whitepaper.
3. A key divergence to note: The whitepaper defines $$d_{asset}=\frac{d_{pt}}{exchangeRate(t)}$$ while in the `calcTrade` function, we define $$d_{asset}=-\frac{d_{pt}}{exchangeRate(t)}$$:

```
int256 preFeeAssetToAccount = netPtToAccount.divDown(preFeeExchangeRate).neg();
```

### Approximation Method for Explicit Fee Calculation

When $$d_{pt}$$ is either above or below zero, the fee computation takes two forms, which can be challenging to implement in a real trading environment. To address this, we propose the following approximation method:
$$
fee=d_{assets}\times fee tier \times yearsToExpiry(t)
$$
 For instance, let’s say Alice wants to swap 1000 USDe → 1100 PT-USDe under the following conditions:

- 6 months before maturity
- AMM Fees: 0.3%
  - We charge 0.3% in APY
- Absolute fees Percentage:   0.3% * 0.5 = 0.15%
- Absolute amount = 1000 * 0.15% = 1.5 USDe

This approximation holds because, as $$feeRateRoot \rightarrow 1$$ (i.e., $$feetier \rightarrow 0$$),  the limits of the following expressions converge to zero:

1. $$lim_{feeRateRoot\rightarrow1}(feeRateRoot-1)\cdot yearsToExpiry(t)=0$$
2. $$lim_{feeRateRoot\rightarrow1}feeRateRoot^{yearsToExpiry(t)}-1=0$$
3. $$lim_{feeRateRoot\rightarrow1}-\frac{1-feeRateRoot^{yearsToExpiry(t)}}{feeRateRoot^{yearsToExpiry(t)}}=0$$

### YT-related Fees

In V2, YT swaps are facilitated through flash swaps within the same pool. Typically, YT swaps incur higher fees than PT swaps.

For example, suppose Bob wants to swap 50 USDe → 1100 YT-USDe:

- This is equivalent to a 1100 PT swap.
- Fees = 1000 USDe \* 0.3% \* 0.5=1.5 USDe.

Even though the amount of assets involved is only 50 USDe, the fees generated are the same as those in Alice’s case, where she swaps 1000 USDe → 1100 PT-USDe.

## Implicit Fees

It is important to clarify that **implicit fees are not caused by the price impact (slippage)** inherent in the AMM model.

### Price Impact

Before diving into the Pendle V2 case, let's first consider Uniswap V2 as an example.

Suppose there is a pool containing $$x$$ amount of A tokens and $$y$$ amount of B tokens. When we use $$dx$$ A tokens to swap for $$dy$$ B tokens, we derive the equation:
$$
(x+dx)(y-dy)=k
$$
Thus, we can express $$dy$$ as:
$$
dy=\frac{y\cdot dx}{x+dx}
$$
In an actual swap, the price of this transaction in terms of B tokens is:
$$
\frac{dx}{dy}=\frac{x+dx}{y}
$$
However, before the swap, the price is $$\frac{x}{y}$$, so the **slippage** is:
$$
Slippage_y=\frac{dx}{dy}-\frac{x}{y}=\frac{dx}{y}
$$
It is obvious that as $$dx$$ increases, becomes larger.

Now, let's return to the Pendle V2 case. According to the `V2_AMM` whitepaper, if a user *u* buys $$d_{pt}$$ PT from the market, the actual swap price is 
$$
\begin{aligned}
\frac{d_{pt}}{d_{asset}}&\equiv exchangeRate_{trade}\\
&=\left(\frac{ln\frac{p_{trade}(t)}{1-p_{trade}(t)}}{rateScalar(t)}+rateAnchor(t)\right)\times or \div feeRateRoot^{yearsToExpiry(t)}
\end{aligned}
$$
where,
$$
p_{trade}(t)=\frac{n_{pt}(t*)-d_{pt}}{n_{pt}(t*)+n_{asset}(t*)}
$$
Before the transaction, the price is 
$$
exchangeRate=\frac{ln\frac{p(t)}{1-p(t)}}{rateScalar(t)}+rateAnchor(t)
$$
Accordingly, the slippage is
$$
\begin{aligned}
Slippage&=exchangeRate_{trade}-exchangeRate
\end{aligned}
$$
Expanding the full expression leads to a more complex derivation. 

### Definition of Implicit Fee

Unfortunately, **implicit fees** are not the same as price impact, as clarified above.

For example, if the current market rate is 15%, a large trade might have an average APY of 16% (1% higher than the market rate). In this case, part of the 1% difference is due to price impact, while the rest is attributable to implicit fees.

If the user splits the large trade into infinitely small amounts, the average APY might drop to 15.8%, for example. Here, 0.8% represents the pure price impact, and 0.2% is the implicit fees.

Thus, we can define implicit fees as follows:

**Implicit Fees** = The additional cost to the user compared to trading an infinitesimally small amount until the full trade is completed, excluding the portion of the cost caused by price impact.

# Efficient Ratio

From a user's perspective, the fee incurred in each transaction is an important consideration. However, from the protocol's point of view, the focus is on the overall fees generated by a pool over time, which reflects its revenue. 

Since pools can differ in terms of start date, expiry date, TVL, underlying assets, and other factors, comparing pools based solely on total fees may not be meaningful. 

Therefore, our team introduces **Efficient Ratio** to assess the **capital efficiency** of specific pools. Below is how it is calculated:


$$
\begin{aligned}
&EfficientRatio=\frac{Average\ Daily\ Swap\ Fee * 365}{ Average\ Daily\ LP\ TVL}
\end{aligned}
$$
It compares the total annualized swap fees to the average daily TVL (Total Value Locked) of the pool. A higher ratio indicates that the pool generates more fees for each unit of liquidity provided, which suggests better operational efficiency.

### How to Understand it?

The efficient ratio is similar to a financial ratio in traditional finance (TradFi): **asset turnover ratio**, which is typically defined as:
$$
\text{Asset Turnover Ratio}=\frac{\text{Sales Revenue}}{\text{Average Total Assets}}
$$
The asset turnover ratio measures how effectively a company uses its total assets to generate revenue. It reflects the amount of sales or revenue generated for every unit of asset employed.

In this context:

- **Annualized Daily Swap Fees** are analogous to revenue.
- **Average Daily LP TVL** corresponds to average total assets.

Thus, the Efficient Ratio serves a similar purpose, indicating how effectively a pool utilizes its assets to generate revenue.

**Additional Considerations**

- Unlike the traditional asset turnover ratio, the numerator in this case is the annualized daily 'revenue,' which helps mitigate the impact of varying pool maturity dates.
- The average daily swap fees encompass all explicit and implicit fees, as well as limit order fees, measuring the overall revenue for all beneficiaries, including Liquidity Providers (LPs) and vePendle voters. Ideally, the denominator should also account for the value of vePendle votes to maintain accuracy. However, for simplicity and ease of interpretation, we focus solely on the LP TVL in the denominator.

# Modeling the Relationship Between FeeTier and EfficientRatio

In this section, we aim to explore the relationship between fee tiers and efficient ratios. We have tried out three different models to capture the statistical relationship. Each of them are followed by sensitivity and heterohestic analyses in the next section.

## Dataset Description

The dataset used in this report can be accessed via the following link:

{% embed url="" %}

**Note:** Data was accessed on February 8, 2025.

### Data Preprocessing

We have preemptively removed 17 pool samples with missing data, including:

- sETH-wstEthSilo 28MAR2024
- vETH-WETH_BalancerLP Aura 26SEP2024
- ether.fi eBTC 27MAR2025
- Venus BNB 26JUN2025
- PENDLE-ETH_Camelot 26JUN2025
- Staking MNT 26DEC2024
- Sophon Farming PEPE 26DEC2024
- mPendle 26DEC2024
- oETH 25DEC2025
- Stargate USDT 27JUN2024
- Stargate USDT 27JUN2024
- gDAI 26DEC2024
- Ethena USDe 31OCT2024
- Ethena sUSDE 31OCT2024
- Zircuit Staking USDe 22AUG2024

- Kyber Elastic axlWstEth-wstETH 28MAR2024
- Staked ePENDLE 26DEC2024

### Descriptive Statistics

Below is a summary of key statistics for the dataset:

| pool               | Fee Tier | AverageIY | Average Daily LP TVL   | Total Swap Fee    | Total Swap Fee (im+ex) | Average Daily Swap Fee | EfficientRatio* | EfficientRatioB** |
| ------------------ | -------- | --------- | ---------------------- | ----------------- | ---------------------- | ---------------------- | --------------- | ----------------- |
| Minimum            | 0.03%    | 2.20%     | 62,036.00              | 96.00             | 207.62                 | 1.45                   | 0.03%           | 0.00%             |
| Maximum            | 3.00%    | 153.40%   | 128,584,588.00         | 1,897,019.00      | 2,471,809.24           | 16,640.52              | 75.19%          | 235.00%           |
| Average            | 0.21%    | 16.25%    | 11,518,886.41          | 64,581.49         | 113,792.33             | 742.86                 | 4.97%           | 14.77%            |
| Median             | 0.10%    | 9.50%     | 4,350,257.00           | 4,464.00          | 9,986.41               | 56.80                  | 1.57%           | 5.00%             |
| Standard Deviation | 0.29%    | 19.12%    | 19,660,958.27          | 182,101.40        | 289,744.22             | 1,965.29               | 9.62%           | 25.05%            |
| Variance           | 0.000008 | 0.04      | 386,553,279,972,616.00 | 33,160,920,898.11 | 83,951,710,675.30      | 3,862,348.99           | 0.01            | 0.06              |
| Skewness           | 5.08     | 4.05      | 3.08                   | 5.86              | 4.55                   | 4.56                   | 4.45            | 4.57              |
| Kurtosis           | 39.53    | 22.78     | 11.05                  | 47.35             | 26.54                  | 25.96                  | 24.38           | 30.36             |

**Statistical Observations**

- **Right-Skewed Distribution (Positive Skewness):** Most variables exhibit strong positive skewness, indicating that the distributions have long right tails. This suggests that while the majority of pools operate within a relatively small range, a few pools have significantly higher values, pulling the mean upward.
- **Leptokurtic Distributions (High Kurtosis):** The kurtosis values for most variables are extremely high (e.g., **Total Swap Fee = 47.35**, **Efficient RatioB = 30.36**), indicating **fat-tailed** distributions. This means that extreme values (outliers) occur more frequently than in a normal distribution. In other words, while most pools cluster around lower values, a few outliers experience extremely high activity.

## Scatter Plot

Before we proceed with modeling the relationship between Fee Tier and Efficient Ratio, we can visually examine their relationship using scatter plots.

Below is the scatter plot showing the Fee Tier vs. Efficient Ratio, categorized by **Base Asset**:

![Scatter Plot of Fee Tier vs. Efficient Ratio (By BaseAsset)](https://cdn.jsdelivr.net/gh/zey9991/mdpic/scatterEffRatioandFeeTierByBaseAsset.png)

Overall, most pools have Fee Tier settings between 0% and 1.0%, particularly within the 0% to 0.5% range. Efficient Ratios are mostly concentrated in the 0% to 20% range. There doesn’t seem to be a very strong monotonic relationship between the two variables, and further analysis during the modeling phase will provide more clarity on the exact nature of the relationship.

When grouped by **Base Asset**, we observe that most BTC-based pools tend to have both lower Fee Tier and Efficient Ratio values. On the other hand, pools with other base assets show more variability in both Fee Tier and Efficient Ratio, with some extreme values even exceeding 40% for Efficient Ratio.

**Yield Source** can be seen as a more detailed categorization of Base Asset. Below is the scatter plot grouped by **Yield Source**:

![Scatter Plot of Fee Tier vs. Efficient Ratio (By YieldSource)](https://cdn.jsdelivr.net/gh/zey9991/mdpic/scatterEffRatioandFeeTierByYieldSource.png)

We can also group the data based on the **chain** to create another scatter plot:

![Scatter Plot of Fee Tier vs. Efficient Ratio (By Chain)](https://cdn.jsdelivr.net/gh/zey9991/mdpic/scatterEffRatioandFeeTierByChain.png)

The majority of pools are deployed on **ETH (id: 1)**, and these pools show considerable variation in both Fee Tier and Efficient Ratio. The next largest group is on **Arbitrum One (id: 42161)**, where the relationship between Fee Tier and Efficient Ratio appears more positively correlated. Other chains have fewer pools, resulting in sparse data points, making it difficult to conclusively assess the relationship. To provide more insight, we can also group the data by both **Base Asset** and **Chain**:

![Scatter Plot of Fee Tier vs. Efficient Ratio (By BaseAsset and Chain)](https://cdn.jsdelivr.net/gh/zey9991/mdpic/scatterEffRatioandFeeTierByBaseAssetandChain.png)

This chart provides a clearer picture:

- On chains like **Op Mainnet (id:10)**, **BSC (id:56)**, **Mantle (id:5000)**, and **Base (id:8453)**, Fee Tier is mostly concentrated between 0% and 1%, with Efficient Ratios typically not very high. In the case of a higher Fee Tier (1%), only a stablecoin asset pool (Ethena USDe 25JUL2024) on the **Mantle** chain has an Efficient Ratio exceeding 20%. Here, the relationship between Fee Tier and Efficient Ratio is closer to a monotonic positive correlation.
- On **Arbitrum One (id:42161)**, where asset types are more diverse, the relationship between Fee Tier and Efficient Ratio also appears to be a monotonic positive correlation. With a 1% Fee Tier, two ETH-based asset pools have an Efficient Ratio greater than 20%.
- The situation on **Ethereum (id:1)** is more complex. While many data points show a positive correlation between Fee Tier and Efficient Ratio, there are still several observations that deviate from this pattern.

Similarly, scatter plots can be created based on **Yield Source** and **Chain**. Since Yield Source is a more granular categorization compared to Base Asset, it serves as a valuable supplement to the previous visualizations:

![Scatter Plot of Fee Tier vs. Efficient Ratio (By YieldSource and Chain)](https://cdn.jsdelivr.net/gh/zey9991/mdpic/scatterEffRatioandFeeTierByYieldSourceandChain.png)

## Polynomial Regression Model

In this section, we consider using a quadratic regression model to attempt to describe the relationship between **Fee Tier** and **Efficient Ratio**, based primarily on the following expectations outlined at the beginning of the paper:

- If the **Fee Tier** is set too high, this will increase the trader's transaction costs. Although LPs and vePendle voters earn more fees per transaction, the overall increase in transaction costs will lead to a decrease in trader activity, which will ultimately reduce the pool's swap fees and lower the **Efficient Ratio**.
- Conversely, if the **Fee Tier** is set too low, it may increase trader activity but results in too little fee income per transaction for LPs and vePendle voters, causing the **Efficient Ratio** to also decrease.

This theory is simple and persuasive. According to this, the relationship between **Fee Tier** and **Efficient Ratio** is expected to exhibit an inverted U-shape (nonlinear relationship). Therefore, we should not use a simple linear regression model, but rather consider a nonlinear model with quadratic or higher-order terms to capture this relationship.

Specifically, we first set up the quadratic regression model as follows:
$$
EfficientRatio=\beta_1+\beta_2FeeTier+\beta_3FeeTier^2+\sum_i \beta_iControls+\epsilon_i
$$
Where:

- $$\beta$$ represents the parameters to be estimated:
  - $$\beta_1$$ is the intercept term of the model. When **Fee Tier** is 0, both **Explicit Fees** and **Limit Order Fees** are 0, so it represents the impact of **Implicit Fees** on the **Efficient Ratio**.
  - We are particularly concerned with the sign of $$\beta_3$$. To demonstrate the inverted U-shape relationship between **Fee Tier** and **Efficient Ratio**, the estimated value of $$\beta_3$$ should be negative.
- $$Controls$$ represents a set of control variables, which include:
  - **Duration** (the pool's lifespan), measured in days. This variable is added to account for the fact that pools are typically more active when they are newly launched, but their trading volume may decline over time, leading to a reduction in the **Efficient Ratio**.
  - **BaseAsset** (the pool's underlying asset): a dummy variable. Market participants may choose different base assets based on market cycles or personal preferences, so we include this variable to capture these effects.
  - We did not include additional dummy variables like **Yield Source** and **Chain** because we found that their inclusion caused perfect multicollinearity among certain variables, which forced us to exclude them. We will explore these variables further in a sensitivity analysis.
- $$\epsilon_i$$ is the error term of the model.

The parameters of the above model can still be estimated using ordinary least squares (OLS), provided the following assumptions hold:

- The model is correctly specified.
- The explanatory variables are nonlinearly correlated.
- The error terms exhibit no autocorrelation.

The estimation results are shown in the table below. To account for potential heteroscedasticity in the error terms, robust standard errors are used. 

For comparison, we also provide the regression results with one to five polynomial terms (the fifth-degree term was omitted due to multicollinearity).

| Variable               | (1) Linear  | (2) Quadratic | (3) Cubic   | (4) Quartic  | (5) Quintic  |
| ---------------------- | ----------- | ------------- | ----------- | ------------ | ------------ |
| **FeeTier**            | 19.16***    | 11.98**       | -8.250      | 0.986        | 0.986        |
|                        | (2.509)     | (5.628)       | (10.90)     | (28.33)      | (28.33)      |
| **FeeTier2**           |             | 566.4         | 3999.2**    | 580.4        | 580.4        |
|                        |             | (360.7)       | (1900.4)    | (9466.9)     | (9466.9)     |
| **FeeTier3**           |             |               | -132549.2*  | 232538.8     | 232538.8     |
|                        |             |               | (71531.9)   | (996142.7)   | (996142.7)   |
| **FeeTier4**           |             |               |             | -10836336.9  | -10836336.9  |
|                        |             |               |             | (29675548.0) | (29675548.0) |
| **FeeTier5**           |             |               |             |              | 0 (omitted)  |
|                        |             |               |             |              | (.)          |
| **DurationDay**        | 0.0000269   | 0.0000158     | -0.00000167 | 0.000000287  | 0.000000287  |
|                        | (0.0000319) | (0.0000296)   | (0.0000241) | (0.0000222)  | (0.0000222)  |
| **BaseAsset==BTC**     | -0.0282**   | -0.0308***    | -0.0311***  | -0.0319***   | -0.0319***   |
|                        | (0.0121)    | (0.0117)      | (0.0117)    | (0.0118)     | (0.0118)     |
| **BaseAsset==ETH**     | 0.000603    | -0.00114      | -0.00284    | -0.00288     | -0.00288     |
|                        | (0.0131)    | (0.0127)      | (0.0122)    | (0.0123)     | (0.0123)     |
| **BaseAsset==Other**   | -0.00681    | -0.0101       | -0.00935    | -0.00895     | -0.00895     |
|                        | (0.0170)    | (0.0169)      | (0.0166)    | (0.0168)     | (0.0168)     |
| **Constant**           | 0.00800     | 0.0208        | 0.0442***   | 0.0383**     | 0.0383**     |
|                        | (0.0153)    | (0.0151)      | (0.00986)   | (0.0192)     | (0.0192)     |
| **Observations**       | 243         | 243           | 243         | 243          | 243          |
| **R-squared**          | 0.234       | 0.240         | 0.253       | 0.253        | 0.253        |
| **Adjusted R-squared** | 0.217       | 0.220         | 0.230       | 0.227        | 0.227        |

***Note*:**  

- **Standard errors** are shown in parentheses below the corresponding coefficient estimates.  
- **Significance levels (p-values):**  
  - \*\*\* represent p < 0.01 (**highly significant**)  
  - \*\* represent p < 0.05 (**moderately significant**)  
  - \* represents p < 0.1 (**weakly significant**)  
  - No stars indicate **p ≥ 0.1**, meaning the result is not statistically significant.  

As seen from the table above, in the quadratic model, the coefficient for the quadratic term is positive but not significant, which rules out a traditional inverted U-shaped relationship between the two variables. However, we cannot rule out the possibility of higher-order terms that could create an inverted U-shape.

Specifically, when a cubic term is added, the quadratic term becomes significant at the 5% level, while the cubic term is significant at the 10% level. Additionally, the cubic model has the lowest adjusted R-squared among the models, as shown in the figure below (if higher fractional powers were included, the curve would be even smoother):

![Adjusted R-Squared vs Polynomial Degree](https://cdn.jsdelivr.net/gh/zey9991/mdpic/Adjusted%20R-Squared%20vs%20Polynomial%20Degree1.png)

**Adjusted R-squared**: Unlike the regular R-squared, which can increase with more variables added to the model (even if those variables are irrelevant), the adjusted R-squared accounts for the number of predictors and introduces a penalty for adding unnecessary terms. This helps to prevent overfitting and provides a more reliable measure of model fit.

Although the coefficient for the linear term is not significant, we can still write out the regression equation:
$$
E(EfficientRatio)=0.0442-8.25FeeTier+3999.2FeeTier^2-132549.2FeeTier^3+\sum_i\hat{\beta_i}Controls
$$
Where:

- $$E(\cdot)$$ represents the expected value of EfficientRatio.
- $$\hat{\beta_i}$$ represents the estimated regression coefficients for the control variables.

Assuming all other control variables take on fixed values (such as the mean or median), we can plot the fitted relationship between FeeTier and EfficientRatio. That is,
$$
E(EfficientRatio|Controls=\text{fixed values})=0.0442-8.25FeeTier+3999.2FeeTier^2-132549.2FeeTier^3+\sum_i\hat{\beta_i}\times \text{fixed values}
$$
We can choose to set all control variables to their median values (instead of the mean, due to the presence of extreme outliers that could distort the average), so:
$$
E(EfficientRatio|Controls=\text{median value})=0.04397-8.25FeeTier+3999.2FeeTier^2-132549.2FeeTier^3
$$
The plot is as follows:

![Predictive Margins with Control Variables at Median Value1](https://cdn.jsdelivr.net/gh/zey9991/mdpic/Predictive%20Margins%20with%20Control%20Variables%20at%20Median%20Value1.png)

From the plot, we can observe that although the cubic regression model doesn't strictly exhibit an inverted U-shape, it does show that as FeeTier increases, the expected EfficientRatio reaches a maximum value of 0.37781 at FeeTier = 0.01902. It's important to note that there is only one sample where FeeTier is greater than 0.01, so the data at this point is sparse. The maximum point may not be stable, and we will further discuss this in the robustness analysis.

Based on the above discussion, we can draw the following conclusions:

- Although the regression results do not show a strict inverted U-shape between EfficientRatio and FeeTier, the cubic model, which provides the best fit, indicates a peak value for EfficientRatio at FeeTier = 0.01902, which partially aligns with our theoretical expectation.
- However, since most of the data points for FeeTier are small, the model may still suffer from estimation bias. The robustness of the model needs further validation.

## Threshold Regression Model

In this section, we abandon the previous assumption of an inverted U-shaped relationship and aim to build a nonlinear model that is more data-driven.

We employ a threshold regression model here. A threshold regression model, as proposed by **Hansen (2000)**, is a piecewise linear model that allows the relationship between the variables to change once a certain threshold is crossed. The basic idea is that the effect of the independent variable on the dependent variable differs across different regimes, defined by the threshold.

Consider the following threshold regression model:
$$
\begin{cases} 
EfficientRatio_i = \beta_1 + \beta_2 \cdot FeeTier +\sum_i\beta_iControls+ \epsilon_i & \text{if } FeeTier \leq \text{Threshold} \\
EfficientRatio_i = \beta_1 + \beta_3 \cdot FeeTier +\sum_i\beta_iControls+  \epsilon_i & \text{if } FeeTier > \text{Threshold}
\end{cases}
$$
We use this model because we hypothesize that the relationship between **FeeTier** and **EfficientRatio** involves a threshold value. When **FeeTier** is below or above the threshold, the relationship is governed by different parameters. Unlike the quadratic regression model, which assumes a continuous nonlinear relationship, the threshold regression model assumes a **piecewise linear** relationship between **FeeTier** and **EfficientRatio**.

First, we need to conduct a threshold effect test to confirm whether a threshold value statistically exists. The LM statistic is used to test this hypothesis.

| **Test of Null of No Threshold Against Alternative of Threshold** | **Value**  |
| ------------------------------------------------------------ | ---------- |
| Number of Bootstrap Replications                             | 5000       |
| Trimming Percentage                                          | 0.15       |
| LM-test for no threshold                                     | 34.4625546 |
| Bootstrap P-Value                                            | 0          |

In the table above, the **Bootstrap P-value** of the LM statistic is similar to the conventional p-value obtained from other econometric methods. Since it is very small (reported as 0), it indicates the presence of a threshold effect. **Trimming Percentage** refers to the percentage of data being trimmed, with the default set to 0.15%.

Next, we estimate the parameters of the threshold regression model as follows:

|                               | Estimate | St Error | t Value | p value | 95% Confidence Interval Lower | 95% Confidence Interval Upper |
| ----------------------------- | -------- | -------- | ------- | ------- | ----------------------------- | ----------------------------- |
| FeeTier(FeeTier ≤ Threshold)  | -13.9097 | 7.4970   | -1.8554 | 0.0653  | -28.6037                      | 0.7843                        |
| Constant(FeeTier ≤ Threshold) | 0.0402   | 0.0090   | 4.4667  | 0.0000  | 0.02259                       | 0.05773                       |
| FeeTier(FeeTier > Threshold)  | 20.9689  | 3.0713   | 6.8274  | 0.0000  | 14.949                        | 26.9887                       |
| Constant(FeeTier > Threshold) | 0.1331   | 0.0871   | 1.5281  | 0.1316  | -0.0376                       | 0.3037                        |
| Threshold Value               | 0.0024   | /        | /       | /       | 0.0024                        | 0.0024                        |

- The estimated threshold value is **0.0024**, which corresponds to the 72.43rd percentile of **FeeTier**. This means that there are 176 samples where **FeeTier** is less than 0.0024 and 67 samples where **FeeTier** is greater than 0.0024. Below is a scatter plot showing the data with the threshold value.
- When **FeeTier ≤ Threshold**, the regression coefficient is -13.9097, which is only significant at the 10% significance level, and the confidence interval is wide and includes 0, suggesting a potential lack of robustness in this estimate.
- When **FeeTier > Threshold**, the regression coefficient is 20.9689, which is significant at the 1% significance level, suggesting a strong positive relationship between **FeeTier** and **EfficientRatio** once the threshold is exceeded.

![scatterThreshold](https://cdn.jsdelivr.net/gh/zey9991/mdpic/scatterThreshold.png)

From the results, we conclude:

- The estimated results show that when **FeeTier** is less than the threshold value of 0.0024 (0.24%), a 0.1% increase in **FeeTier** corresponds to a 1.39% decrease in **EfficientRatio**. However, when **FeeTier** exceeds the threshold, a 0.1% increase in **FeeTier** leads to a 2.10% increase in **EfficientRatio**.
- The effect of **FeeTier** on **EfficientRatio** first decreases and then increases as **FeeTier** rises, forming a **V-shaped** curve.
- This result initially seems completely opposite to our previous expectation of an inverted U-shape.

The above results indicate the existence of a single threshold value but do not rule out the possibility of multiple thresholds. According to Hansen's paper, after excluding the 176 samples below the first threshold, we conduct another threshold effect test on the remaining 67 sub-samples. The Bootstrap P-value is very large (the result is not presented in this report), suggesting that there are no multiple threshold values.

The following table presents the goodness of fit for the threshold regression model:

|              | FeeTier ≤ 0.0024 | FeeTier > 0.0024 | Linear Model |
| ------------ | ---------------- | ---------------- | ------------ |
| Observations | 176              | 67               | 243.0000     |
| R-squared    | 0.0340           | 0.3685           | 0.2340       |

- **R-squared for FeeTier ≤ 0.0024 is very low, at just 3.4%**: While R-squared is not the most crucial metric in causal inference compared to predictive tasks, it can provide a useful indication of the model's explanatory power. In this case, the low R-squared suggests that the model does a poor job explaining the relationship between FeeTier and EfficientRatio when FeeTier is less than or equal to 0.0024. This could be due to factors such as a small sample size, the model not adequately capturing the complexity of the nonlinear relationship, or the presence of omitted variables. Moreover, this R-squared value is noticeably lower than that of the linear regression model (R² = 0.2340), highlighting that the threshold regression model performs poorly in this region.
- **R-squared for FeeTier > 0.0024 is much higher, at 36.85%**: In contrast, when FeeTier exceeds 0.0024, the model performs significantly better, with an R-squared of 0.3685. This is notably higher than the 3.4% for the lower FeeTier range and also exceeds the R-squared of the linear regression model (0.2340). This indicates that, when FeeTier is greater than the threshold, the relationship between FeeTier and EfficientRatio is clearer and better captured by the model, suggesting that the model fits the data well in this range.

### Why does this phenomenon occur?

- **Parameter estimation errors**: The regression coefficient when **FeeTier ≤ Threshold** is only significant at the 10% significance level, and the wide confidence interval that includes 0 suggests potential estimation errors. Additionally, the goodness of fit for this part of the model is poor, with a very low R-squared (3.4%) indicating that the model struggles to explain the relationship between FeeTier and EfficientRatio in this range. This could be due to small sample sizes or incorrect model specification, which may lead to results that significantly differ from expectations. The low R-squared value in this range also suggests that the model does not adequately capture the complexity of the relationship, or there might be omitted variables influencing the results.
- **If parameter estimation errors are ruled out**, this might suggest that when **FeeTier** is set close to the threshold, while LPs and vePendle voters are attracted to higher fees, the increase in **Swap Fees** generated by traders does not reach a higher level, leading to a further decrease in **EfficientRatio**. 
- This effect, although counterintuitive, indicates that when setting **FeeTier**, we should avoid values close to the threshold. In simpler terms, one should either choose a very low or very high **FeeTier**, as values near the threshold might not be optimal.

## **Semiparametric Estimation**

The previous two models inevitably face the risk of **model misspecification**. To address this concern, this section further relaxes the assumptions imposed on the model, allowing the data to reveal more of its inherent structure and reducing the bias introduced by potential misspecification.

Specifically, both of the previous models rely on **parametric estimation**, which implicitly assumes a specific distribution of the data and focuses entirely on estimating the associated parameters. *(This was not explicitly mentioned in the report because, under large sample sizes, the **Central Limit Theorem (CLT)** ensures that the estimators are asymptotically consistent, meaning they converge to the true values. Moreover, while we previously acknowledged that estimation errors could arise due to insufficient sample size, our dataset is sufficiently large for CLT to hold.)*

To further relax these assumptions, we can remove the parametric constraints on data distribution—essentially admitting that we **know nothing** about the true distribution—and employ **nonparametric estimation** to analyze the relationship between **FeeTier** and **EfficientRatio**. However, a purely nonparametric approach has its own drawbacks:

- Although control variables (such as **Duration**) can still be incorporated, doing so significantly reduces **estimation efficiency**, requiring a much larger sample size.
- Conversely, if we omit control variables, we cannot rule out the possibility that these factors influence the relationship between **FeeTier** and **EfficientRatio**, leading to omitted variable bias.

To navigate this trade-off, we adopt a **semiparametric estimation method**, specifically the **partially linear model (PLM)**, which is specified as follows:
$$
EfficientRatio_i=f(FeeTier)+\sum_i\beta_iControls+\epsilon_i
$$
where:

- $$f(\cdot)$$ represents an **unknown function** of **FeeTier**, with no assumptions on its functional form.

- This model still assumes that:
  1. **Control variables** enter the model in a **linear form**, allowing us to estimate their coefficients while remaining agnostic about the functional relationship between **FeeTier** and **EfficientRatio**.
  2. **Error terms exhibit no autocorrelation**.

The estimation procedure can be intuitively understood as follows:

- First, we estimate the regression coefficients for the **linear** variables.
- Next, we compute the residuals—the portion of the dependent variable **EfficientRatio** that remains unexplained by the linear controls.
- Finally, we attribute this residual variation to the **nonparametric** component and estimate it accordingly.

The **parametric estimation results** and **goodness-of-fit metrics** for the partially linear model (PLM) are presented below, along with the corresponding results from a standard **linear regression model** for comparison：

| Variable             | (1) PLM     | (2) Linear  |
| -------------------- | ----------- | ----------- |
| **FeeTier**          |             | 19.16***    |
|                      |             | (2.402)     |
| **Duration**         | 0.00000438  | 0.0000269   |
|                      | (0.0000246) | (0.0000336) |
| **BaseAsset==BTC**   | -0.0303***  | -0.0282     |
|                      | (0.0109)    | (0.0204)    |
| **BaseAsset==ETH**   | -0.00119    | 0.000603    |
|                      | (0.0125)    | (0.0132)    |
| **BaseAsset==Other** | -0.00651    | -0.00681    |
|                      | (0.0170)    | (0.0183)    |
| **Constant**         |             | 0.00800     |
|                      |             | (0.0138)    |
| **Observations**     | 243         | 243         |
| **R-squared**        | 0.011       | 0.234       |

***Note*:**  

- **Standard errors** are shown in parentheses below the corresponding coefficient estimates.  
- **Significance levels (p-values):**  
  - \*\*\* represent p < 0.01 (**highly significant**)  
  - \*\* represent p < 0.05 (**moderately significant**)  
  - \* represents p < 0.1 (**weakly significant**)  
  - No stars indicate **p ≥ 0.1**, meaning the result is not statistically significant.  

Although the table shows that the R² for the **parametric component** of the PLM is quite low (only **0.011**), this does not imply that the model itself is weak. The reported **R²** reflects only the goodness of fit for the **parametric portion** (i.e., the linear controls) and does not account for the explanatory power of the **nonparametric component** (e.g., the kernel regression part). Thus, while the nonparametric component may significantly contribute to explaining variations in the dependent variable, its effect is not captured by the reported **R²** value.

To further evaluate whether the **nonparametric fit** can be well approximated by a **parametric adjustment**, we conduct **Härdle and Mammen’s (1993) specification test**. The null hypothesis states that *parametric and nonparametric fits are not significantly different*.

| **Polynomial Order** | Approximate p-value |
| -------------------- | ------------------- |
| 1                    | 0.08                |
| 2                    | 0.10                |
| 3                    | 0.35                |

As shown in the table, when the **polynomial order reaches 3**, we can no longer reject the null hypothesis at the **90% confidence level**. This suggests that a **third-order polynomial** may provide a reasonable parametric approximation of the nonparametric model.

The following figure illustrates the **nonparametric kernel regression** of **EfficientRatio** on **FeeTier**, capturing the flexible, data-driven relationship without imposing a specific functional form.

![Kernel Regression Plot of EfficientRatio against FeeTier](https://cdn.jsdelivr.net/gh/zey9991/mdpic/Kernel%20Regression%20Plot%20of%20EfficientRatio%20against%20FeeTier.png)

The **shaded area** in the figure represents the **95% confidence interval**.

From the above discussion, we can conclude that:

- From the plot, we observe that **EfficientRatio** and **FeeTier** exhibit an approximately **monotonic increasing** relationship, suggesting a **positive correlation** between the two variables.
- On the other hand, since we cannot reject the null hypothesis that the nonparametric model can be approximated by the cubic polynomial model, this model **can be considered as a complement to the previous cubic model results**. In the plot, except at the right endpoint of the range, no strict maximum value is observed. This further indicates that the cubic model requires further robustness checks or sensitivity analysis to ensure the validity of the results.

## Conclusions



# References

1. [MarketMathCore.sol - WORKSPACE - Blockscan contract source code viewer](https://vscode.blockscan.com/ethereum/0x40789E8536C668c6A249aF61c81b9dfaC3EB8F32)
2. [PendleMarketV3.sol - WORKSPACE - Blockscan contract source code viewer](https://vscode.blockscan.com/ethereum/0x40789E8536C668c6A249aF61c81b9dfaC3EB8F32)
3. [Sci-Hub |SAMPLE SPLITTING AND THRESHOLD ESTIMATION by Hansen ](https://sci-hub.st/10.2307/2999601)